{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR CFS Features extraction\n",
    "\n",
    "https://sleepdata.org/datasets/cfs/pages/equipment/montage-and-sampling-rate-information.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "730\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yasa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pingouin as pg\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "from scipy.signal import hilbert\n",
    "from mne.filter import filter_data\n",
    "\n",
    "from tensorpac import methods as tpm\n",
    "from tensorpac import EventRelatedPac\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(font_scale=1.25)\n",
    "\n",
    "from helper_functions import get_sub_visit_hyp\n",
    "\n",
    "# Define paths\n",
    "root_dir = '/Volumes/NSRR/cfs/'\n",
    "eeg_dir = root_dir + 'polysomnography/edfs/'\n",
    "hypno_dir = root_dir + 'polysomnography/annotations-events-profusion/'\n",
    "\n",
    "# List all EDF files\n",
    "all_edfs = os.listdir(eeg_dir)\n",
    "all_edfs = all_edfs = [c for c in os.listdir(eeg_dir) if c.endswith(\".edf\")]\n",
    "all_subj = [c.split(\"-\")[2][:-4] for c in all_edfs]\n",
    "\n",
    "print(len(all_subj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = []\n",
    "df_erpac = []\n",
    "include = ['C3', 'M2']\n",
    "sf = 100\n",
    "\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "for i, sub in enumerate(tqdm(all_subj)):\n",
    "    \n",
    "    eeg_file = eeg_dir + 'cfs-visit5-' + str(sub) + '.edf'\n",
    "    hypno_file = hypno_dir + 'cfs-visit5-' + str(sub) + '-profusion.xml'\n",
    "    \n",
    "    # Check that file exists\n",
    "    if not os.path.isfile(eeg_file):\n",
    "        warnings.warn(\"File not found %s\" % eeg_file)\n",
    "        continue\n",
    "    if not os.path.isfile(hypno_file):\n",
    "        warnings.warn(\"File not found %s\" % hypno_file)\n",
    "        continue\n",
    "\n",
    "    # LOAD EEG DATA\n",
    "    try:\n",
    "        raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "        raw.drop_channels(np.setdiff1d(raw.info['ch_names'], include))\n",
    "        raw.load_data()\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "    # Resample to 100 Hz and low-pass filter \n",
    "    raw.resample(sf, npad=\"auto\")\n",
    "    \n",
    "    # Re-reference to C3-M2\n",
    "    raw.set_eeg_reference([\"M2\"])\n",
    "    raw.drop_channels(['M2'])\n",
    "\n",
    "    # LOAD HYPNOGRAM\n",
    "    hypno, sf_hyp = yasa.load_profusion_hypno(hypno_file)\n",
    "    # Check that hypno and data have the same number of epochs\n",
    "    n_epochs = hypno.shape[0]\n",
    "    if n_epochs != np.floor(raw.n_times / sf / 30):\n",
    "        warnings.warn(\"Hypno and data size do not match. Skipping subject.\")\n",
    "        continue\n",
    "        \n",
    "    # Set NREM is 6\n",
    "    hypno_NREM = pd.Series(hypno).replace({2: 6, 3: 6}).to_numpy()\n",
    "        \n",
    "    # Upsample hypno NREM\n",
    "    hypno_NREM_up = yasa.hypno_upsample_to_data(hypno_NREM, sf_hyp, raw)\n",
    "    \n",
    "    # Extract C3 data\n",
    "    data = np.squeeze(raw.get_data(units=\"uV\"))\n",
    "    assert data.ndim == 1\n",
    "    \n",
    "    # Invert polarity\n",
    "    # http://zzz.bwh.harvard.edu/luna/vignettes/nsrr-polarity/\n",
    "    data *= -1\n",
    "    \n",
    "    #################################\n",
    "    # PHASE-AMPLITUDE COUPLING\n",
    "    #################################\n",
    "    \n",
    "    # Slow-waves detection in NREM (N2 + N3)\n",
    "    ptp_thr = 60\n",
    "    neg_amp = round(ptp_thr / 1.875)\n",
    "    freq_sw = (0.3, 1.5)\n",
    "    freq_sp = (12, 16)\n",
    "    sw = yasa.sw_detect(\n",
    "            data, sf, ch_names=[\"EEG\"], hypno=hypno_NREM_up, include=6, freq_sw=freq_sw,\n",
    "            dur_neg=(0.3, 1.5), dur_pos=(0.1, 1), amp_neg=(neg_amp, 200),\n",
    "            amp_pos=(10, 200), amp_ptp=(ptp_thr, 300), coupling=False,\n",
    "            freq_sp=freq_sp, remove_outliers=True\n",
    "    )\n",
    "    \n",
    "    if sw is None:\n",
    "        warnings.warn(\"No SOs detected for %s. SKIPPING SUBJECT.\" % sub)\n",
    "        continue\n",
    "        \n",
    "    # Spindles detection in NREM (N2 + N3)\n",
    "    sp = yasa.spindles_detect(\n",
    "            data, sf, ch_names=[\"EEG\"], hypno=hypno_NREM_up, include=6, duration=(0.4, 2), \n",
    "            thresh={'rel_pow': 0.05, 'corr': 0.50, 'rms': 2}, remove_outliers=True)\n",
    "    \n",
    "    if sp is None:\n",
    "        warnings.warn(\"No spindles detected for %s. SKIPPING SUBJECT.\" % sub)\n",
    "        continue\n",
    "        \n",
    "    sp_sum = sp.summary(grp_stage=True)\n",
    "        \n",
    "    # Co-occurring slow-waves / spindles and get summary\n",
    "    sw_sum = sw.find_cooccurring_spindles(sp.summary())\n",
    "    sw_sum = sw.summary(grp_chan=False, grp_stage=True)\n",
    "    \n",
    "    # Assert that we have at least 5 slow-waves, otherwise skip subject\n",
    "    if sw._events.shape[0] <= 5:\n",
    "        warnings.warn(\"Less than 5 SOs detected for %s. SKIPPING SUBJECT.\" % sub)\n",
    "        continue\n",
    "    \n",
    "    # PAC using only +/- 1 second around negative peak, as in Mikutta et al 2021 (J. Sleep Research)\n",
    "    data_sp = filter_data(\n",
    "        sw._data, sf, 12, 16, method='fir', l_trans_bandwidth=1.5,\n",
    "        h_trans_bandwidth=1.5, verbose=0)\n",
    "    amp = np.squeeze(np.abs(hilbert(data_sp)))\n",
    "    pha = np.squeeze(np.angle(hilbert(sw._data_filt)))\n",
    "    \n",
    "    # Get epochs\n",
    "    idx_pks = (sw._events['NegPeak'] * sf).to_numpy().astype(int)  # In samples\n",
    "    idx_epochs = yasa.get_centered_indices(amp, idx_pks, npts_before=sf, npts_after=sf)[0]\n",
    "    \n",
    "    amp = amp[idx_epochs][None, ...]  # shape (n_freqs, n_epochs, n_samples)\n",
    "    pha = pha[idx_epochs][None, ...]\n",
    "    \n",
    "    # Calculate raw PAC and preferred phase\n",
    "    ndp = np.squeeze(tpm.norm_direct_pac(pha, amp, p=1))\n",
    "    ndp_thr = np.squeeze(tpm.norm_direct_pac(pha, amp))  # Unreliable values are set to 0\n",
    "    idx_thr_supzero = np.nonzero(ndp_thr)\n",
    "    ndp_thr_supzero = ndp_thr[idx_thr_supzero]\n",
    "    pp = np.squeeze(tpm.preferred_phase(pha, amp, n_bins=18)[1])\n",
    "    pp_thr_supzero = pp[idx_thr_supzero]\n",
    "    \n",
    "    # Append to output dict\n",
    "    output_dict = {\n",
    "        \"dataset\": \"cfs\",\n",
    "        \"subj\": sub,\n",
    "        # Spindles\n",
    "        \"sp_density\": sp_sum.loc[6, \"Density\"],\n",
    "        \"sp_power\": sp_sum.loc[6, \"RelPower\"],\n",
    "        \"sp_freq\": sp_sum.loc[6, \"Frequency\"],\n",
    "        # Slow-waves\n",
    "        \"sw_density\": sw_sum.loc[6, \"Density\"],\n",
    "        \"sw_ptp\": sw_sum.loc[6, \"PTP\"],\n",
    "        \"sw_freq\": sw_sum.loc[6, \"Frequency\"],\n",
    "        \"sw_ndpac\": np.nanmean(ndp),\n",
    "        \"sw_ndpac_thr\": np.nanmean(ndp_thr),\n",
    "        \"sw_ndpac_thr_supzero\": np.nanmean(ndp_thr_supzero),\n",
    "        \"sw_ndpac_prop_supzero\": ndp_thr_supzero.size / ndp_thr.size,\n",
    "        \"sw_pp\": pg.circ_mean(pp),\n",
    "        \"sw_pp_thr_supzero\": pg.circ_mean(pp_thr_supzero),\n",
    "        \"sw_coinc_spindles\": sw_sum.loc[6, \"CooccurringSpindle\"],\n",
    "    }\n",
    "\n",
    "    # Append to main dataframe\n",
    "    df.append(output_dict)\n",
    "    \n",
    "    #################################\n",
    "    # ERPAC\n",
    "    #################################\n",
    "    \n",
    "    # Calculate event-related PAC\n",
    "    # Get peak-locked data +/- 3 seconds before negative peak of each slow-waves\n",
    "    # Events that are outside the bound of data are masked in \"idx_epochs\"\n",
    "    idx_epochs, idx_valid = yasa.get_centered_indices(\n",
    "        data, idx_pks, npts_before=int(3 * sf), npts_after=int(3 * sf))\n",
    "    \n",
    "    if idx_valid.size != idx_pks.size:\n",
    "        warnings.warn(\"Some events-locked windows are outside the edge of data. Skipping subject %s for ERPAC.\" % sub)\n",
    "        continue\n",
    "        \n",
    "    # Extract an example of a coupled SO and an uncoupled one\n",
    "    if i == 0:\n",
    "        df_so_example = pd.DataFrame({\n",
    "            \"sp_coupling\": data_sp[0, idx_epochs[600]][200:401],\n",
    "            \"so_coupling\": sw._data_filt[0, idx_epochs[600]][200:401],\n",
    "            \"sp_nocoup\": data_sp[0, idx_epochs[269]][200:401],\n",
    "            \"so_nocoup\": sw._data_filt[0, idx_epochs[269]][200:401]})\n",
    "        \n",
    "        df_so_example.to_csv(\"output/csv/df_example_so.csv\", index=False)\n",
    "\n",
    "    # Keep only events with ndPAC>0\n",
    "    idx_epochs = idx_epochs[idx_thr_supzero]\n",
    "\n",
    "    # Average slow-waves\n",
    "    avg_sw = np.squeeze(sw._data_filt[:, idx_epochs]).mean(0)\n",
    "    time = np.arange(len(avg_sw)) / sf\n",
    "    \n",
    "    df_avg_sw = pd.DataFrame({\n",
    "        \"subj\": sub,\n",
    "        \"time\": time,\n",
    "        \"avg_sw\": avg_sw,\n",
    "    })\n",
    "    \n",
    "    # ERPAC (+/- 3 sec to avoid filter edge)\n",
    "    data_erpac = data[idx_epochs] \n",
    "    erp = EventRelatedPac(f_pha=[0.3, 1.5], f_amp=np.arange(4.75, 25.75, 0.5), verbose=False)  # f_pha = 0.8 Hz\n",
    "    freqs = erp.f_amp.mean(1).astype(str)\n",
    "    pha = erp.filter(sf, data_erpac, ftype='phase')\n",
    "    amp = erp.filter(sf, data_erpac, ftype='amplitude')\n",
    "    erpac = np.squeeze(erp.fit(pha, amp, method=\"circular\"))  # Fast\n",
    "    ergcpac = np.squeeze(erp.fit(pha, amp, method=\"gc\", smooth=50))  # Slow -- Gaussian Copula\n",
    "    \n",
    "    # Merge into a single dataframe\n",
    "    erpac = pd.DataFrame(erpac.T)\n",
    "    erpac.columns = freqs\n",
    "    erpac = erpac.add_prefix(\"circ_\")\n",
    "    erpac['time'] = time\n",
    "    \n",
    "    ergcpac = pd.DataFrame(ergcpac.T)\n",
    "    ergcpac.columns = freqs\n",
    "    ergcpac = ergcpac.add_prefix(\"gc_\")\n",
    "    ergcpac['time'] = time\n",
    "    \n",
    "    df_erpac.append(df_avg_sw.merge(erpac, how=\"inner\").merge(ergcpac, how=\"inner\"))\n",
    "    \n",
    "    # Save ERPAC dataframe every 10 subjects\n",
    "    if i % 20 == 0:\n",
    "        pd.concat(df_erpac).set_index(['subj', 'time']).to_parquet(\"output/csv/df_cfs_ERGCPAC_inverted.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df).set_index([\"dataset\", \"subj\"])\n",
    "df.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"output/csv/df_cfs_coupling_NREM_inverted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save ER(GC)PAC\n",
    "pd.concat(df_erpac).set_index(['subj', 'time']).to_parquet(\"output/csv/df_cfs_ERGCPAC_inverted.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
