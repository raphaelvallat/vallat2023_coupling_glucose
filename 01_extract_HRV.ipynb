{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NSRR HRV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import yasa\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from mne.io import read_raw_edf\n",
    "from neurokit2 import ecg_clean, ecg_peaks\n",
    "from neurokit2.misc import NeuroKitWarning\n",
    "from neurokit2 import hrv_time, hrv_frequency\n",
    "from helper_functions import get_sub_visit_hyp, get_all_edfs\n",
    "\n",
    "# Define paths\n",
    "root_dir = '/Volumes/NSRR/'\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=NeuroKitWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: The HRV is pre-computed in MESA. This script is only used for CFS.\n",
    "for dataset in ['cfs']:\n",
    "    \n",
    "    df = []\n",
    "    \n",
    "    # Extract all EDF files\n",
    "    all_edfs, hypno_dir = get_all_edfs(dataset, root_dir)\n",
    " \n",
    "    # Include\n",
    "    if dataset == \"mesa\":\n",
    "        include = [\"EKG\"]\n",
    "    elif dataset == \"cfs\":\n",
    "        include = [\"ECG1\"]\n",
    "        \n",
    "    for eeg_file in tqdm(all_edfs):\n",
    "\n",
    "        # Extract subject, visit and hypno_file from fname\n",
    "        sub, visit, hypno_file = get_sub_visit_hyp(eeg_file, dataset, hypno_dir)\n",
    "\n",
    "        # Check that file exists\n",
    "        if not os.path.isfile(eeg_file):\n",
    "            warnings.warn(\"File not found %s\" % eeg_file)\n",
    "            continue\n",
    "        if not os.path.isfile(hypno_file):\n",
    "            warnings.warn(\"File not found %s\" % hypno_file)\n",
    "            continue\n",
    "\n",
    "        # LOAD EEG DATA\n",
    "        try:\n",
    "            raw = read_raw_edf(eeg_file, preload=False, verbose=0)\n",
    "            raw.drop_channels(np.setdiff1d(raw.info['ch_names'], include))\n",
    "            raw.load_data()\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        sf = raw.info['sfreq']\n",
    "        \n",
    "        # LOAD HYPNOGRAM\n",
    "        hypno, _ = yasa.load_profusion_hypno(hypno_file)\n",
    "        if not len(hypno[hypno > 0]):\n",
    "            continue\n",
    "\n",
    "        # Get VALID hypnograms, excluding Motion and Unscored\n",
    "        hypno_ALL = (hypno >= 0).astype(int)  # 0 / 1\n",
    "\n",
    "        # Extract EKG data\n",
    "        data = raw.get_data()[0] * 1e6\n",
    "        \n",
    "        # Inverse polarity\n",
    "        data *= -1\n",
    "\n",
    "        # Find non-overlapping, continuous epoch of 5 min of NREM sleep\n",
    "        idx_start, idx_stop = [], []\n",
    "        thresh = 10  # 10 epochs = 5 min\n",
    "        for i in np.arange(0, hypno_ALL.size - thresh + 1, step=thresh):\n",
    "            if i+thresh > hypno_ALL.size:\n",
    "                continue\n",
    "            epochs = hypno_ALL[i:i+thresh]\n",
    "            if (epochs == 1).all():\n",
    "                idx_start.append(i)\n",
    "                idx_stop.append(i+thresh)\n",
    "\n",
    "        if not len(idx_start):\n",
    "            warnings.warn(\"No continuous epochs of 5 min were found for subject %s | SKIPPING SUBJECT\" % sub)\n",
    "            continue\n",
    "\n",
    "        epochs = np.vstack((idx_start, idx_stop)).T\n",
    "        epochs_sample = (epochs * (30 * sf)).astype(int)\n",
    "\n",
    "        #################################\n",
    "        # HRV REM\n",
    "        #################################\n",
    "\n",
    "        # Loop across 5 min epochs\n",
    "        hrv_all_epochs = []\n",
    "\n",
    "        for start, stop in epochs_sample:\n",
    "\n",
    "            # 1) Epoching\n",
    "            ecg_epoch = data[start:stop]\n",
    "            if ecg_epoch.size != (sf * 5 * 60):\n",
    "                continue\n",
    "\n",
    "            # 2) IBI detection\n",
    "            try:\n",
    "                ecg_cleaned = ecg_clean(ecg_epoch, sf, method=\"neurokit\")\n",
    "                signals, info = ecg_peaks(ecg_cleaned, sf, method=\"neurokit\", correct_artifacts=True)\n",
    "                rpeaks = info['ECG_R_Peaks']\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            # 3) Check RR data\n",
    "            rpeaks = np.unique(rpeaks)\n",
    "            # We require at least 175 valid peaks, i.e. average HR of 35 bpm ((175 / 300) * 60\n",
    "            if rpeaks.size < 175:\n",
    "                continue\n",
    "\n",
    "            # 4) Calculate HRV\n",
    "            try:\n",
    "                td = hrv_time(rpeaks, sf)\n",
    "                fd = hrv_frequency(rpeaks, sf)\n",
    "                hrv_all_epochs.append(pd.concat((td, fd), axis=1))\n",
    "            except:\n",
    "                warnings.warn(\"Error calculating HRV features for %s\" % sub)\n",
    "                continue\n",
    "        \n",
    "        # Average across epochs using the median\n",
    "        # Only if at least 3 epochs were found to average, otherwise skip subject\n",
    "        if len(hrv_all_epochs) < 3:\n",
    "            continue\n",
    "\n",
    "        hrv_all_epochs = pd.concat(hrv_all_epochs)\n",
    "        hrv_subj = hrv_all_epochs.median().to_dict()\n",
    "        hrv_subj['dataset'] = dataset\n",
    "        hrv_subj['subj'] = sub\n",
    "        hrv_subj['visit'] = visit\n",
    "        hrv_subj['n_epochs'] = hrv_all_epochs.shape[0]\n",
    "        df.append(hrv_subj)\n",
    "\n",
    "    # Create and export dataframe for each study\n",
    "    df = pd.DataFrame(df).set_index(['dataset', 'subj', 'visit'])\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df = df.add_suffix(\"_ALL\")\n",
    "    df.to_csv(\"output/csv/df_HRV_ALL_%s.csv\" % dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
